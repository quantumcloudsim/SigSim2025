{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5430da8b-49fa-4239-a386-16dac9df6cd8",
   "metadata": {},
   "source": [
    "## Section 6 - Evaluation Part 1 \n",
    "The following script presents the first use case from Section 6 Part 1 – Evaluation in the manuscript where we simulate the current IBM quantum cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f1691-d35f-4622-bcc4-e570c3fa58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QCloud import *\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def print_result(job_records, LAMBDA): \n",
    "    finished = defaultdict(int)\n",
    "    unfinished = defaultdict(int)\n",
    "    wait_time = defaultdict(list)\n",
    "    never_assigned = 0\n",
    "    fidelity = defaultdict(list)\n",
    "\n",
    "    avg_fidelity = defaultdict(int)\n",
    "    std_fidelity = defaultdict(int)\n",
    "    avg_waittime = defaultdict(int)\n",
    "    std_waittime = defaultdict(int)\n",
    "\n",
    "    for events in job_records.values():\n",
    "        if 'arrival' in events and 'devc_start' in events and 'devc_finish' in events:            \n",
    "            devc_name = events['devc_name'] \n",
    "            finished[devc_name] += 1\n",
    "            wait_time_diff = events['devc_finish']-events['devc_start']\n",
    "            wait_time[devc_name].append(wait_time_diff)\n",
    "        elif 'arrival' in events and 'devc_start' in events and 'devc_finish' not in events:\n",
    "            devc_name = events['devc_name']\n",
    "            unfinished[devc_name] += 1        \n",
    "        elif 'arrival' in events and 'devc_start' not in events:        \n",
    "            never_assigned += 1\n",
    "        if 'fidelity' in events: \n",
    "            devc_name = events['devc_name']\n",
    "            fidelity[devc_name].append(events['fidelity'])\n",
    "\n",
    "\n",
    "    \n",
    "    total_job_processed = 0\n",
    "    with open(f\"results/counted-jobs-lambda-{LAMBDA}.txt\", \"w\") as file:\n",
    "        file.write(f\"LAMBDA: {LAMBDA}\\n\")\n",
    "\n",
    "        for key in finished.keys(): \n",
    "            avg_fidelity[key] = statistics.mean(fidelity[key])\n",
    "            std_fidelity[key] = statistics.stdev(fidelity[key])\n",
    "            avg_waittime[key] = round(statistics.mean(wait_time[key]), 4)\n",
    "            std_waittime[key] = round(statistics.stdev(wait_time[key]), 4)\n",
    "\n",
    "            total_job_processed += finished[key]\n",
    "            \n",
    "            # print(f\"device name: {key}, finished: {finished[key]}, avg_fidelity: {avg_fidelity[key]:.4f} +/- {std_fidelity[key]:.4f}, avg_waittime: {avg_waittime[key]:.4f} +/- {std_waittime[key]:.4f}\")    \n",
    "            file.write(f\"device name: {key}, processed jobs by machine: {finished[key]}, avg_fidelity: {avg_fidelity[key]:.4f} +/- {std_fidelity[key]:.4f}, avg_waittime: {avg_waittime[key]:.4f} +/- {std_waittime[key]:.4f}\\n\")\n",
    "        print(f\"LAMBDA: {LAMBDA} | Total job processed: {total_job_processed} | Never Assigned: {never_assigned}\", )    \n",
    "        file.write(f\"Total job processed: {total_job_processed} | Never Assigned: {never_assigned}\\n\")\n",
    "          \n",
    "    sorted_finished = {key: finished[key] for key in sorted(finished, key=lambda x: int(x))}\n",
    "    sorted_avg_waittime = {key: avg_waittime[key] for key in sorted(avg_waittime, key=lambda x: int(x))}\n",
    "    sorted_avg_fidelity = {key: avg_fidelity[key] for key in sorted(avg_fidelity, key=lambda x: int(x))} \n",
    "    sorted_std_fidelity = {key: std_fidelity[key] for key in sorted(std_fidelity, key=lambda x: int(x))}\n",
    "    \n",
    "    throughput = list(sorted_finished.values())\n",
    "    wait_time = list(sorted_avg_waittime.values())\n",
    "    avg_fidelity = list(sorted_avg_fidelity.values())\n",
    "    std_fidelity = list(sorted_std_fidelity.values())\n",
    "    \n",
    "    print(\"processed jobs by machine:\", throughput)\n",
    "    print(\"wait_time:\", wait_time)\n",
    "    \n",
    "    return total_job_processed, never_assigned, throughput, wait_time, avg_fidelity, std_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89178a-511c-44a6-9c2d-e57405c30923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGINNING OF THE SIMULATION\n",
    "sim_start_time = time.time()\n",
    "LAMBDAS = [0.5, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "processed = defaultdict(list)\n",
    "notprocessed = defaultdict(list)\n",
    "tot_troughput = defaultdict(list)\n",
    "avg_wait_time = defaultdict(list)\n",
    "avg_fidelity_ = defaultdict(int)\n",
    "std_fidelity_ = defaultdict(int)\n",
    "SAVE_RAW_DATA = False\n",
    "\n",
    "for i in range(10): \n",
    "    for LAMBDA in LAMBDAS: \n",
    "        # Create quantum devices\n",
    "        ibm_kawasaki = IBM_Kawasaki(env=None, name=\"1\", printlog = False)\n",
    "        ibm_kyiv = IBM_Kyiv(env=None, name=\"2\", printlog = False)\n",
    "        ibm_sherbrooke = IBM_Sherbrooke(env=None, name=\"3\", printlog = False)\n",
    "        ibm_quebec = IBM_Quebec(env=None, name=\"4\", printlog = False)\n",
    "        ibm_rensselaer = IBM_Rensselaer(env=None, name=\"5\", printlog = False)\n",
    "        ibm_brisbane = IBM_Brisbane(env=None, name=\"6\", printlog = False)        \n",
    "        ibm_brussels = IBM_Brussels(env=None, name=\"7\", printlog = False)\n",
    "        ibm_strasbourg = IBM_Strasbourg(env=None, name=\"8\", printlog = False)        \n",
    "        ibm_marrakesh = IBM_Marrakesh(env=None, name=\"9\", printlog = False) \n",
    "        ibm_fez = IBM_Fez(env=None, name=\"10\", printlog = False)\n",
    "        ibm_torino = IBM_Torino(env=None, name=\"11\", printlog = False)\n",
    "\n",
    "\n",
    "        expovar_model = lambda: random.expovariate(lambd=LAMBDA)\n",
    "        devices = [ibm_kawasaki, ibm_kyiv, ibm_sherbrooke, ibm_quebec, ibm_rensselaer, \n",
    "                  ibm_brisbane, ibm_brussels, ibm_strasbourg, ibm_marrakesh, ibm_fez, ibm_torino]\n",
    "\n",
    "        start_time = time.time() # Start the timer\n",
    "\n",
    "        # Initialize and run the simulation using jobs from a CSV file\n",
    "        qcloudsimenv = QCloudSimEnv(\n",
    "            devices=devices,\n",
    "            broker_class=ParallelBroker,\n",
    "            job_feed_method=\"generator\",\n",
    "            job_generation_model=expovar_model\n",
    "        )\n",
    "        qcloudsimenv.run(until=10080)\n",
    "\n",
    "        end_time = time.time() # End the timer\n",
    "        elapsed_time = end_time - start_time # Calculate elapsed time\n",
    "\n",
    "        print(f\"Elapsed time: {elapsed_time:.5f} seconds\\n\")\n",
    "        # Access job records after the simulation\n",
    "        job_records = qcloudsimenv.job_records_manager.get_job_records()\n",
    "\n",
    "        # If you want to save raw data, set the parameter to True\n",
    "        if SAVE_RAW_DATA: \n",
    "            with open(f\"results/raw_records-lambda-{LAMBDA}.txt\", \"w\") as file:\n",
    "                file.write(f\"Elapsed time: {elapsed_time:.5f} seconds\\n\")\n",
    "                for job_id, events in job_records.items():\n",
    "                    # Write each job record to the file               \n",
    "                    file.write(f\"Job ID: {job_id}, Events: {events}\\n\")\n",
    "                    \n",
    "        processedjobs, notprocessedjobs, throughput, wait_time, avg_fidelity, std_fidelity = print_result(job_records, LAMBDA)\n",
    "        processed[LAMBDA] = processedjobs\n",
    "        notprocessed[LAMBDA] = notprocessedjobs\n",
    "        tot_troughput[LAMBDA] = throughput\n",
    "        avg_wait_time[LAMBDA] = wait_time\n",
    "        avg_fidelity_[LAMBDA] = avg_fidelity\n",
    "        std_fidelity_[LAMBDA] = std_fidelity\n",
    "        \n",
    "sim_end_time = time.time() # End the timer\n",
    "sim_elapsed_time = sim_end_time - sim_start_time # Calculate elapsed time\n",
    "\n",
    "print(f\"Elapsed time: {sim_elapsed_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa4593-115b-4fe5-ab15-b5b19f4b3675",
   "metadata": {},
   "source": [
    "### Plotting Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bfc88-7dae-4826-948e-a6ab790046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_names = [\"ibm_kawasaki\", \"ibm_kyiv\", \"ibm_sherbrooke\", \"ibm_quebec\", \"ibm_rensselaer\", \n",
    "\"ibm_brisbane\", \"ibm_brussels\", \"ibm_strasbourg\", \"ibm_marrakesh\", \"ibm_fez\", \"ibm_torino\"]\n",
    "\n",
    "# Settings\n",
    "datasets1 = [tot_troughput[1], tot_troughput[2], tot_troughput[3], tot_troughput[4], tot_troughput[5], tot_troughput[6]]\n",
    "datasets2 = [avg_wait_time[1], avg_wait_time[2], avg_wait_time[3], avg_wait_time[4], avg_wait_time[5], avg_wait_time[6]]\n",
    "labels = ['λ = 1', 'λ = 2', 'λ = 3', 'λ = 4', 'λ = 5', 'λ = 6']\n",
    "colors = [\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#FF7F00\", \"#984EA3\", \"#FFFF33\"]\n",
    "\n",
    "num_devices = len(device_names)\n",
    "x = np.arange(num_devices)\n",
    "width = 0.15\n",
    "\n",
    "# Create vertically stacked subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# ----- Plot 1: Total QJobs Throughput -----\n",
    "for i, dataset in enumerate(datasets1):\n",
    "    axs[0].bar(x + i * width, dataset, width, label=labels[i], color=colors[i])\n",
    "\n",
    "axs[0].set_ylabel('Total QJobs\\nThroughput', fontsize=14)\n",
    "axs[0].set_ylim(0, 3400)\n",
    "axs[0].legend(loc='upper left', bbox_to_anchor=(0, 1), ncol=2)\n",
    "axs[0].tick_params(axis='x', labelbottom=False)  # hide x labels for top plot\n",
    "\n",
    "# ----- Plot 2: Average Wait Time -----\n",
    "for i, df in enumerate(datasets2):\n",
    "    axs[1].bar(x + i * width, df, width, label=labels[i], capsize=5, color=colors[i])\n",
    "\n",
    "axs[1].set_xlabel('QDevices', fontsize=14)\n",
    "axs[1].set_ylabel('Average\\nWait Time', fontsize=14)\n",
    "axs[1].set_ylim(0, 280)\n",
    "axs[1].set_xticks(x + width * 1.5)\n",
    "axs[1].set_xticklabels(device_names, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig-6-throughput-waittime-IBM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9fff6-cf86-4053-b66d-c872712392ec",
   "metadata": {},
   "source": [
    "### Plotting Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32013e4f-3721-4314-918b-777cfec878a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKERSIZE = 5\n",
    "FONTSIZE = 10\n",
    "# Data\n",
    "lambdas = [0.5, 1, 2, 3, 4, 5, 6]\n",
    "processed_jobs = list(processed.values())\n",
    "not_processed_jobs = list(notprocessed.values())\n",
    "\n",
    "color = ['#56B4E9', '#E69F00']\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 2.4))\n",
    "\n",
    "# Plot the lines for processed and not processed jobs\n",
    "plt.plot(lambdas, processed_jobs, label='Processed QJobs', marker='s', color=\"#377EB8\", linewidth=2, markersize=MARKERSIZE)\n",
    "plt.plot(lambdas, not_processed_jobs, label='Never Assigned QJobs', marker='d', color=\"#E41A1C\", linewidth=2, markersize=MARKERSIZE)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Job arrival rate (λ)', fontsize=FONTSIZE)\n",
    "plt.ylabel('Number of QJobs\\n Processed', fontsize=FONTSIZE)\n",
    "plt.xticks(lambdas, fontsize=FONTSIZE)\n",
    "plt.yticks(fontsize=FONTSIZE)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=FONTSIZE)\n",
    "plt.savefig(\"Fig-7-throughputs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18712d2-4576-4ae9-b3a2-0ba588ba63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All average fidelities and standard deviations\n",
    "avg_fidelities = list(avg_fidelity_.values())\n",
    "std_devs = list(std_fidelity_.values())\n",
    "\n",
    "# Flatten the lists\n",
    "all_fidelities = np.concatenate(avg_fidelities)\n",
    "all_std_devs = np.concatenate(std_devs)\n",
    "\n",
    "# Calculate variances\n",
    "variances = all_std_devs**2\n",
    "\n",
    "# Calculate weights (w = 1/variance)\n",
    "weights = 1 / variances\n",
    "\n",
    "# Calculate weighted average fidelity\n",
    "weighted_avg_fidelity = np.sum(weights * all_fidelities) / np.sum(weights)\n",
    "\n",
    "# Calculate overall standard deviation\n",
    "overall_std_dev = np.sqrt(1 / np.sum(weights))\n",
    "\n",
    "print(f\"Weighted Average Fidelity: {weighted_avg_fidelity:.4f}\")\n",
    "print(f\"Overall Standard Deviation: {overall_std_dev:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
