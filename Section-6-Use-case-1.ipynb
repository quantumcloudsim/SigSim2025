{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5430da8b-49fa-4239-a386-16dac9df6cd8",
   "metadata": {},
   "source": [
    "## Section 6 - Evaluation Part 1 \n",
    "The following script presents the first use case from Section 6 Part 1 – Evaluation in the manuscript where we simulate the current IBM quantum cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f1691-d35f-4622-bcc4-e570c3fa58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QCloud import *\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def print_result(job_records, LAMBDA): \n",
    "    finished = defaultdict(int)\n",
    "    unfinished = defaultdict(int)\n",
    "    wait_time = defaultdict(list)\n",
    "    never_assigned = 0\n",
    "    fidelity = defaultdict(list)\n",
    "\n",
    "    avg_fidelity = defaultdict(int)\n",
    "    std_fidelity = defaultdict(int)\n",
    "    avg_waittime = defaultdict(int)\n",
    "    std_waittime = defaultdict(int)\n",
    "\n",
    "    for events in job_records.values():\n",
    "        if 'arrival' in events and 'devc_start' in events and 'devc_finish' in events:            \n",
    "            devc_name = events['devc_name'] \n",
    "            finished[devc_name] += 1\n",
    "            wait_time_diff = events['devc_finish']-events['devc_start']\n",
    "            wait_time[devc_name].append(wait_time_diff)\n",
    "        elif 'arrival' in events and 'devc_start' in events and 'devc_finish' not in events:\n",
    "            devc_name = events['devc_name']\n",
    "            unfinished[devc_name] += 1        \n",
    "        elif 'arrival' in events and 'devc_start' not in events:        \n",
    "            never_assigned += 1\n",
    "        if 'fidelity' in events: \n",
    "            devc_name = events['devc_name']\n",
    "            fidelity[devc_name].append(events['fidelity'])\n",
    "\n",
    "\n",
    "    \n",
    "    total_job_processed = 0\n",
    "    with open(f\"results/counted-jobs-lambda-{LAMBDA}.txt\", \"w\") as file:\n",
    "        file.write(f\"LAMBDA: {LAMBDA}\\n\")\n",
    "\n",
    "        for key in finished.keys(): \n",
    "            avg_fidelity[key] = statistics.mean(fidelity[key])\n",
    "            std_fidelity[key] = statistics.stdev(fidelity[key])\n",
    "            avg_waittime[key] = round(statistics.mean(wait_time[key]), 4)\n",
    "            std_waittime[key] = round(statistics.stdev(wait_time[key]), 4)\n",
    "\n",
    "            total_job_processed += finished[key]\n",
    "            \n",
    "            # print(f\"device name: {key}, finished: {finished[key]}, avg_fidelity: {avg_fidelity[key]:.4f} +/- {std_fidelity[key]:.4f}, avg_waittime: {avg_waittime[key]:.4f} +/- {std_waittime[key]:.4f}\")    \n",
    "            file.write(f\"device name: {key}, processed jobs by machine: {finished[key]}, avg_fidelity: {avg_fidelity[key]:.4f} +/- {std_fidelity[key]:.4f}, avg_waittime: {avg_waittime[key]:.4f} +/- {std_waittime[key]:.4f}\\n\")\n",
    "        print(f\"LAMBDA: {LAMBDA} | Total job processed: {total_job_processed} | Never Assigned: {never_assigned}\", )    \n",
    "        file.write(f\"Total job processed: {total_job_processed} | Never Assigned: {never_assigned}\\n\")\n",
    "          \n",
    "    sorted_finished = {key: finished[key] for key in sorted(finished, key=lambda x: int(x))}\n",
    "    sorted_avg_waittime = {key: avg_waittime[key] for key in sorted(avg_waittime, key=lambda x: int(x))}\n",
    "    sorted_avg_fidelity = {key: avg_fidelity[key] for key in sorted(avg_fidelity, key=lambda x: int(x))} \n",
    "    sorted_std_fidelity = {key: std_fidelity[key] for key in sorted(std_fidelity, key=lambda x: int(x))}\n",
    "    \n",
    "    throughput = list(sorted_finished.values())\n",
    "    wait_time = list(sorted_avg_waittime.values())\n",
    "    avg_fidelity = list(sorted_avg_fidelity.values())\n",
    "    std_fidelity = list(sorted_std_fidelity.values())\n",
    "    \n",
    "    print(\"processed jobs by machine:\", throughput)\n",
    "    print(\"wait_time:\", wait_time)\n",
    "    \n",
    "    return total_job_processed, never_assigned, throughput, wait_time, avg_fidelity, std_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89178a-511c-44a6-9c2d-e57405c30923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGINNING OF THE SIMULATION\n",
    "sim_start_time = time.time()\n",
    "LAMBDAS = [0.5, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "processed = defaultdict(list)\n",
    "notprocessed = defaultdict(list)\n",
    "tot_troughput = defaultdict(list)\n",
    "avg_wait_time = defaultdict(list)\n",
    "avg_fidelity_ = defaultdict(int)\n",
    "std_fidelity_ = defaultdict(int)\n",
    "SAVE_RAW_DATA = False\n",
    "\n",
    "for i in range(10): \n",
    "    for LAMBDA in LAMBDAS: \n",
    "        # Create quantum devices\n",
    "        ibm_kawasaki = IBM_Kawasaki(env=None, name=\"1\", printlog = False)\n",
    "        ibm_kyiv = IBM_Kyiv(env=None, name=\"2\", printlog = False)\n",
    "        ibm_sherbrooke = IBM_Sherbrooke(env=None, name=\"3\", printlog = False)\n",
    "        ibm_quebec = IBM_Quebec(env=None, name=\"4\", printlog = False)\n",
    "        ibm_rensselaer = IBM_Rensselaer(env=None, name=\"5\", printlog = False)\n",
    "        ibm_brisbane = IBM_Brisbane(env=None, name=\"6\", printlog = False)        \n",
    "        ibm_brussels = IBM_Brussels(env=None, name=\"7\", printlog = False)\n",
    "        ibm_strasbourg = IBM_Strasbourg(env=None, name=\"8\", printlog = False)        \n",
    "        ibm_marrakesh = IBM_Marrakesh(env=None, name=\"9\", printlog = False) \n",
    "        ibm_fez = IBM_Fez(env=None, name=\"10\", printlog = False)\n",
    "        ibm_torino = IBM_Torino(env=None, name=\"11\", printlog = False)\n",
    "\n",
    "\n",
    "        expovar_model = lambda: random.expovariate(lambd=LAMBDA)\n",
    "        devices = [ibm_kawasaki, ibm_kyiv, ibm_sherbrooke, ibm_quebec, ibm_rensselaer, \n",
    "                  ibm_brisbane, ibm_brussels, ibm_strasbourg, ibm_marrakesh, ibm_fez, ibm_torino]\n",
    "\n",
    "        start_time = time.time() # Start the timer\n",
    "\n",
    "        # Initialize and run the simulation using jobs from a CSV file\n",
    "        qcloudsimenv = QCloudSimEnv(\n",
    "            devices=devices,\n",
    "            broker_class=ParallelBroker,\n",
    "            job_feed_method=\"generator\",\n",
    "            job_generation_model=expovar_model\n",
    "        )\n",
    "        qcloudsimenv.run(until=10080)\n",
    "\n",
    "        end_time = time.time() # End the timer\n",
    "        elapsed_time = end_time - start_time # Calculate elapsed time\n",
    "\n",
    "        print(f\"Elapsed time: {elapsed_time:.5f} seconds\\n\")\n",
    "        # Access job records after the simulation\n",
    "        job_records = qcloudsimenv.job_records_manager.get_job_records()\n",
    "\n",
    "        # If you want to save raw data, set the parameter to True\n",
    "        if SAVE_RAW_DATA: \n",
    "            with open(f\"results/raw_records-lambda-{LAMBDA}.txt\", \"w\") as file:\n",
    "                file.write(f\"Elapsed time: {elapsed_time:.5f} seconds\\n\")\n",
    "                for job_id, events in job_records.items():\n",
    "                    # Write each job record to the file               \n",
    "                    file.write(f\"Job ID: {job_id}, Events: {events}\\n\")\n",
    "                    \n",
    "        processedjobs, notprocessedjobs, throughput, wait_time, avg_fidelity, std_fidelity = print_result(job_records, LAMBDA)\n",
    "        processed[LAMBDA] = processedjobs\n",
    "        notprocessed[LAMBDA] = notprocessedjobs\n",
    "        tot_troughput[LAMBDA] = throughput\n",
    "        avg_wait_time[LAMBDA] = wait_time\n",
    "        avg_fidelity_[LAMBDA] = avg_fidelity\n",
    "        std_fidelity_[LAMBDA] = std_fidelity\n",
    "        \n",
    "sim_end_time = time.time() # End the timer\n",
    "sim_elapsed_time = sim_end_time - sim_start_time # Calculate elapsed time\n",
    "\n",
    "print(f\"Elapsed time: {sim_elapsed_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0671f-50be-40f3-bbba-1ff790123ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_names = [\"ibm_kawasaki\", \"ibm_kyiv\", \"ibm_sherbrooke\", \"ibm_quebec\", \"ibm_rensselaer\", \n",
    "\"ibm_brisbane\", \"ibm_brussels\", \"ibm_strasbourg\", \"ibm_marrakesh\", \"ibm_fez\", \"ibm_torino\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815dd91-d941-4c86-adc6-3a2c197be5cd",
   "metadata": {},
   "source": [
    "### Plotting Figure 6 (top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d78ca-ed33-4cd0-aa8a-ffe5715b9da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of datasets and corresponding labels\n",
    "# value_counts_0_5 = [363, 367, 372, 408, 395, 473, 411, 456, 477, 495, 458]\n",
    "value_counts_1 = tot_troughput[1]\n",
    "value_counts_2 = tot_troughput[2]\n",
    "value_counts_3 = tot_troughput[3]\n",
    "value_counts_4 = tot_troughput[4]\n",
    "value_counts_5 = tot_troughput[5]\n",
    "value_counts_6 = tot_troughput[6]\n",
    "\n",
    "datasets = [value_counts_1, value_counts_2, value_counts_3, value_counts_4, value_counts_5, value_counts_6]\n",
    "labels = ['λ = 1', 'λ = 2', 'λ = 3', 'λ = 4', 'λ = 5', 'λ = 6']  # Labels for each dataset\n",
    "colors = [\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#FF7F00\", \"#984EA3\", \"#FFFF33\"]   # suggested by chatGPT (color blind friendly)\n",
    "\n",
    "# Number of devices (assuming this matches the length of your 'Devices' column)\n",
    "num_devices = len(device_names)\n",
    "\n",
    "# Create an array of positions for the x-axis (one for each device)\n",
    "x = np.arange(num_devices)\n",
    "\n",
    "# Define the width of the bars (adjust depending on the number of datasets)\n",
    "width = 0.15  # Width of each bar\n",
    "\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "\n",
    "# Plot each dataset\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Plot bars for each dataset\n",
    "    plt.bar(x + i * width, dataset, width, label=labels[i], color=colors[i])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('QDevices', fontsize=14)\n",
    "plt.ylabel('Total QJobs\\n Throughput', fontsize=14)\n",
    "# plt.title('Total Jobs Processed for Different Lambda Values', fontsize=16)\n",
    "\n",
    "# Set custom x-tick labels using the device names from averages_df\n",
    "plt.xticks(ticks=x + width * 1.5, labels=device_names, rotation=45, ha='right', fontsize=14)\n",
    "plt.ylim(0, 3400)\n",
    "\n",
    "# Add legend to differentiate between datasets\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig-6-throughput-IBM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead50cf-df16-413f-9239-b6a243a98cd9",
   "metadata": {},
   "source": [
    "### Plotting Figure 6 (Bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574e849-b467-495a-b3f1-460f1ac0830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the dataframes for easier iteration\n",
    "\n",
    "datasets = [avg_wait_time[1], avg_wait_time[2], avg_wait_time[3], avg_wait_time[4], avg_wait_time[5], avg_wait_time[6]]\n",
    "labels = ['λ = 1', 'λ = 2', 'λ = 3', 'λ = 4', 'λ = 5', 'λ = 6']  # Labels for the legend\n",
    "# colors = [\"#f5b7b1\", \"#d2b4de\", \"#85c1e9\", \"#a9dfbf\", \"#f7dc6f\", \"#ccd1d1\"]   \n",
    "colors = [\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#FF7F00\", \"#984EA3\", \"#FFFF33\"] # suggested by chatGPT (color blind friendly)\n",
    "\n",
    "# Number of devices\n",
    "num_devices = len(device_names)\n",
    "\n",
    "# Create an array of positions for the x-axis (one for each device)\n",
    "x = np.arange(num_devices)\n",
    "\n",
    "# Define width of bars (adjust depending on number of datasets)\n",
    "width = 0.15  # Width of each bar\n",
    "\n",
    "plt.figure(figsize=(12, 1.75))\n",
    "\n",
    "# Plot each dataset\n",
    "for i, df in enumerate(datasets):\n",
    "    plt.bar(x + i * width, df, width, label=labels[i], capsize=5, color=colors[i])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('QDevices', fontsize=14)\n",
    "plt.ylabel('Average\\n Wait Time', fontsize=14)\n",
    "\n",
    "# Set custom x-tick labels using the device names from the first dataset (assuming all datasets have the same devices)\n",
    "plt.xticks(ticks=x + width * 1.5, labels=device_names, rotation=45, ha='right', fontsize=12)\n",
    "plt.ylim(0, 280)\n",
    "\n",
    "# Add legend to differentiate between datasets\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0.8, 1.3))\n",
    "plt.savefig(\"Fig-6-waittime-IBM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9fff6-cf86-4053-b66d-c872712392ec",
   "metadata": {},
   "source": [
    "### Plotting Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32013e4f-3721-4314-918b-777cfec878a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKERSIZE = 5\n",
    "FONTSIZE = 10\n",
    "# Data\n",
    "lambdas = [0.5, 1, 2, 3, 4, 5, 6]\n",
    "processed_jobs = list(processed.values())\n",
    "not_processed_jobs = list(notprocessed.values())\n",
    "\n",
    "color = ['#56B4E9', '#E69F00']\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 2.4))\n",
    "\n",
    "# Plot the lines for processed and not processed jobs\n",
    "plt.plot(lambdas, processed_jobs, label='Processed QJobs', marker='s', color=\"#377EB8\", linewidth=2, markersize=MARKERSIZE)\n",
    "plt.plot(lambdas, not_processed_jobs, label='Never Assigned QJobs', marker='d', color=\"#E41A1C\", linewidth=2, markersize=MARKERSIZE)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Job arrival rate (λ)', fontsize=FONTSIZE)\n",
    "plt.ylabel('Number of QJobs\\n Processed', fontsize=FONTSIZE)\n",
    "plt.xticks(lambdas, fontsize=FONTSIZE)\n",
    "plt.yticks(fontsize=FONTSIZE)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=FONTSIZE)\n",
    "plt.savefig(\"Fig-7-throughputs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18712d2-4576-4ae9-b3a2-0ba588ba63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All average fidelities and standard deviations\n",
    "avg_fidelities = list(avg_fidelity_.values())\n",
    "std_devs = list(std_fidelity_.values())\n",
    "\n",
    "# Flatten the lists\n",
    "all_fidelities = np.concatenate(avg_fidelities)\n",
    "all_std_devs = np.concatenate(std_devs)\n",
    "\n",
    "# Calculate variances\n",
    "variances = all_std_devs**2\n",
    "\n",
    "# Calculate weights (w = 1/variance)\n",
    "weights = 1 / variances\n",
    "\n",
    "# Calculate weighted average fidelity\n",
    "weighted_avg_fidelity = np.sum(weights * all_fidelities) / np.sum(weights)\n",
    "\n",
    "# Calculate overall standard deviation\n",
    "overall_std_dev = np.sqrt(1 / np.sum(weights))\n",
    "\n",
    "print(f\"Weighted Average Fidelity: {weighted_avg_fidelity:.4f}\")\n",
    "print(f\"Overall Standard Deviation: {overall_std_dev:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
